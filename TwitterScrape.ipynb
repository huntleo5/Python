{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (1) Create a JSON File of Your Credentials\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Please create your own credential JSON file in the current directory.\n",
    "\n",
    "    At first, you need to create a dictionary of your credentials.\n",
    "\n",
    "    Second, you need to create a JSON file (i.e. twitter_credentials.json) of your credentials.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credential ={ \n",
    "    \"API_KEY\": \"VqR9HJemANJ893BekWXTxXWT7\", \n",
    "    \"API_SECRET\": \"gfAdxfdXj3eP9xH1XzwkKlcs7tQ6x2q68yzQRP4gOzuDu3t0iF\", \n",
    " \"ACCESS_TOKEN\": \"1244356645393707024-YgjM3PKRbwc65oFmmgdyEFNSkhoHqF\", \n",
    " \"ACCESS_TOKEN_SECRET\": \"LJLnwmw65iMuZnR2ULsU5RQq8Edfu4f1oHUilW3If9TTe\"\n",
    "}\n",
    "credential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "outfile = open('twitter_credentials.json', 'w')\n",
    "json.dump(credential, outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (2) Collect 1K Tweets of Your Keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Please choose your own keyword to collect 1K tweets.\n",
    "\n",
    "    Please collect 1K tweets. Please use a code in Data_Collection_Twitter_API.ipynb\n",
    "    \n",
    "    You will have \"tweet_stream_KEYWORD_1000.json\" in your working folder. \n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = credential['API_KEY']\n",
    "API_SECRET = credential['API_SECRET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "outfile = open('tweet_stream_elon_1000.json', 'w')\n",
    "json.dump(credential, outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from twython import TwythonStreamer\n",
    "import sys\n",
    "import json\n",
    "\n",
    "container = []\n",
    "\n",
    "class MyStream(TwythonStreamer):\n",
    "    def on_success(self, data):\n",
    "        if 'text' in data:\n",
    "            print(data['text'])\n",
    "            container.append(data)\n",
    "\n",
    "        if len(container) == 1000:\n",
    "            self.store_json()\n",
    "            self.disconnect()\n",
    "            \n",
    "    def on_error(self, status_code, data):\n",
    "        print(status_code)\n",
    "        self.disconnect()\n",
    "        \n",
    "    def store_json(self):\n",
    "        infile = open('tweet_stream_{}_{}.json'.format(keyword, len(container)), 'w')\n",
    "        json.dump(container, infile)\n",
    "        infile.close()\n",
    "\n",
    "infile = open('twitter_credentials.json')\n",
    "credentials = json.load(infile)\n",
    "infile.close()\n",
    "    \n",
    "API_KEY = credentials['API_KEY']\n",
    "API_SECRET = credentials['API_SECRET']\n",
    "ACCESS_TOKEN = credentials['ACCESS_TOKEN']\n",
    "ACCESS_TOKEN_SECRET = credentials['ACCESS_TOKEN_SECRET']\n",
    "\n",
    "stream = MyStream(API_KEY, API_SECRET, ACCESS_TOKEN, ACCESS_TOKEN_SECRET)\n",
    "\n",
    "keyword = 'elon'\n",
    "\n",
    "stream.statuses.filter(track = keyword)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (3) Read JSON file for Prelinimary Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Please read your JSON file (i.e. tweet_stream_KEYWORD_1000.json);\n",
    "    and assign it to \"data\" variable.\n",
    "    \n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import Counter\n",
    "from pprint import pprint\n",
    "\n",
    "infile = open('tweet_stream_elon_1000.json')\n",
    "data = json.load(infile)\n",
    "infile.close\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (4) Preliminary Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    What are the ten most popular hashtags (#hashtag)?\n",
    "\n",
    "'''\n",
    "\n",
    "# note: you need to import Counter object from collections module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in data:\n",
    "    for h in t['entities']['hashtags']:\n",
    "        print(h['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtag_list = []\n",
    "for t in data:\n",
    "    for h in t['entities']['hashtags']:\n",
    "        if t != '':\n",
    "            hashtag_list.append(t['user']['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(hashtag_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = Counter(hashtag_list)\n",
    "\n",
    "c.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Q5. Who is the most fequently tweeting person about the topic?\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_list = []\n",
    "for t in data:\n",
    "    if t != '':\n",
    "        name_list.append(t['user']['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(name_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = Counter(name_list)\n",
    "\n",
    "c.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (5) Create Word Cloud from Your 1K Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Please (1) read your JSON file (i.e. tweet_stream_KEYWORD_1000.json), and assign it to \"contents\" variable,\n",
    "           (2) generate a word cloud image from the \"contents\" variable.\n",
    "           \n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile = open('tweet_stream_elon_1000.json')\n",
    "contents = json.load(infile)\n",
    "infile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contents1 = ''\n",
    "\n",
    "for t in contents:\n",
    "    contents1 += t['text'] + '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud = WordCloud(max_font_size = 80, collocations = False).generate(contents1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Plesae (1) display the generated word cloud image and\n",
    "           (2) save the image as wordcloud_new.pdf\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis('off')\n",
    "plt.savefig('wordcloud_new.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
